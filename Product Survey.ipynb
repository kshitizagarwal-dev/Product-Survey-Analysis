{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "This is our dataset that contains:-\n",
    "    1. Timestamp,\n",
    "    2. Your Age,\n",
    "    3. Gender,\n",
    "    4. State you reside in,\n",
    "    5. City you reside in\n",
    "    6. Product(s) you like/wish to purchase,\n",
    "    7. Do you like to visit to parties more frequently.\n",
    "    \n",
    "In total we contain 210 rows and 7 columns out of which 6 are  of our use.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data = pd.read_csv('Customer Feedback (Responses) - Form responses 1 (1).csv')\n",
    "\n",
    "df_raw_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "#### Droping the TimeStamp Column as it of no use for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-508e94dea07c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_raw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Timestamp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Thing(s) on which you spend most of the time of your day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "df_raw_data.drop(['Timestamp','Thing(s) on which you spend most of the time of your day'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.rename(columns = {'Your Age' : 'Age',\n",
    "                              'State you reside in' : 'State',\n",
    "                              'City you reside in' : 'City',\n",
    "                              'Product(s) you like/wish to purchase' : 'Product_Purchase',\n",
    "                              'Do you like to visit to parties more frequently?' : 'Party'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.Product_Purchase.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.Product_Purchase.replace(to_replace = 'Headphones/Earphones ', value = 'Headphones/Earphones', inplace = True)\n",
    "df_raw_data.Product_Purchase.replace(to_replace = 'Headphones/Earphone', value = 'Headphones/Earphones', inplace = True)\n",
    "df_raw_data.Product_Purchase.replace(to_replace = ' Books', value = 'Books', inplace = True)\n",
    "df_raw_data.Product_Purchase.replace(to_replace = ' Shoes', value = 'Shoes', inplace = True)\n",
    "df_raw_data.Product_Purchase.replace(to_replace = ' Smartwatch', value = 'Smartwatch', inplace = True)\n",
    "df_raw_data.Product_Purchase.replace(to_replace = 'Wallet, Shoes', value = 'Shoes', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funtion to get the info about data .\n",
    "def get_df_info(df, include_unique_values = False):\n",
    "    col_name_list = list(df.columns)\n",
    "    col_type_list = [type(df[col][0]) for col in col_name_list]\n",
    "    col_null_count_list = [df[col].isnull().sum() for col in col_name_list]\n",
    "    col_unique_count_list = [df[col].nunique() for col in col_name_list]\n",
    "    col_memory_usage_list = [df[col].memory_usage(deep = True) for col in col_name_list]\n",
    "    df_total_memory_usage = sum(col_memory_usage_list)/1048576\n",
    "    if include_unique_values :\n",
    "        col_unqiue_values_list = [df[col].unique() for col in col_name_list]\n",
    "        df_info = pd.DataFrame({'column_name' : col_name_list, 'column_type': col_type_list,\n",
    "                                'null_count': col_null_count_list, 'nunique':col_unique_count_list,\n",
    "                                'unique_values' : col_unqiue_values_list\n",
    "                               })\n",
    "    else:\n",
    "         df_info = pd.DataFrame({'column_name' : col_name_list, 'column_type': col_type_list,\n",
    "                                'null_count': col_null_count_list, 'nunique':col_unique_count_list\n",
    "                                }) \n",
    "    return df_info, df_total_memory_usage\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_info , df_raw_data_total_memory_usage = get_df_info(df_raw_data, True)\n",
    "df_raw_data_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing\n",
    "#### Everything is in string So we will map into numeric using the cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_copy = df_raw_data.copy()\n",
    "df_raw_data_copy = df_raw_data_copy.astype('category')\n",
    "df_raw_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_copy_info , df_raw_data_copy_total_memory_usage = get_df_info(df_raw_data_copy, True)\n",
    "df_raw_data_copy_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_raw_data_copy.columns:\n",
    "    df_raw_data_copy[c] = df_raw_data_copy[c].cat.codes\n",
    "df_raw_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_copy_info , df_raw_data_copy_total_memory_usage = get_df_info(df_raw_data_copy, True)\n",
    "df_raw_data_copy_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    " Here, Product_Purchase is Y-variable or label\n",
    " And,  All others are X-variable or features\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA \n",
    "#### Doing correlation on data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_copy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "There are total of 200 entries(or rows).\n",
    "Maximum People are of UttarPradesh(15) about 50 to 75%.\n",
    "Maximum people belongs to Tier2 city(1).\n",
    "Most of the people like to do party.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA through  data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.heatmap(df_raw_data_copy.corr(), cmap = 'coolwarm', annot = True, vmin = -1, vmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above is the correlation graph , through it we get to know that \n",
    "#### the highly correlated value with 'Product_Purchase' is city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lmplot(data = df_raw_data_copy, x = 'Product_Purchase', y = 'Age')\n",
    "plt.yticks(ticks = np.arange(0, 4), labels = ['0-17', '18-30', '30-45', '45 and above'])\n",
    "plt.xticks(ticks = np.arange(0,7), labels = ['Headphones/Earphones','Books', 'Smartwatch', 'Shoes', 'OTT subscriptions', 'Perfume','Wallet'], rotation = 'vertical' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lmplot(data = df_raw_data_copy, x = 'Product_Purchase', y = 'City')\n",
    "plt.yticks(ticks = np.arange(0, 3), labels = ['Tier1', 'Tier2', 'Tier3'])\n",
    "plt.xticks(ticks = np.arange(0,7), labels = ['Headphones/Earphones','Books', 'Smartwatch', 'Shoes', 'OTT subscriptions', 'Perfume','Wallet'], rotation = 'vertical' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.lmplot(data = df_raw_data_copy, x = 'Product_Purchase', y = 'Party')\n",
    "plt.yticks(ticks = np.arange(0, 2), labels = ['No', 'Yes'])\n",
    "plt.xticks(ticks = np.arange(0,7), labels = ['Headphones/Earphones','Books', 'Smartwatch', 'Shoes', 'OTT subscriptions', 'Perfume','Wallet'], rotation = 'vertical' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating machine learning models.\n",
    "##### We are using r2_score and mean_absolute_error metrices to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as LR \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_eval_table(model_attrib):\n",
    "    df_model_eval = pd.DataFrame({'model': model_attrib['model_names'],\n",
    "                                  'feature_count': model_attrib['model_feature_counts'], \n",
    "                                  'feature_names': model_attrib['model_feature_names'], \n",
    "                                  'r2': model_attrib['model_r2_scores'], \n",
    "                                  'mae': model_attrib['model_mae_scores']})\n",
    "    return df_model_eval.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attrib = {\n",
    "    'model_names': [],\n",
    "    'model_feature_counts': [],\n",
    "    'model_feature_names': [],\n",
    "    'model_r2_scores': [],\n",
    "    'model_mae_scores': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model 1 with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = df_raw_data_copy.loc[:, ['Age', 'Gender', 'State', 'City', 'Party'] ]\n",
    "\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test= train_test_split(X_data, df_raw_data_copy.Product_Purchase, random_state = 0)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression model\n",
    "lr_model_1 = LR()\n",
    "lr_model_1.fit(X_train, Y_train)\n",
    "y_hat_lr_model_1 = lr_model_1.predict(X_test)\n",
    "model_attrib['model_names'].append('lr_model_1')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_lr_model_1))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_lr_model_1))\n",
    "\n",
    "#RandomForestRegressor\n",
    "rf_model_1 = RFR(random_state = 0)\n",
    "rf_model_1.fit(X_train, Y_train)\n",
    "y_hat_rf_model_1 = rf_model_1.predict(X_test)\n",
    "model_attrib['model_names'].append('rf_model_1')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_rf_model_1))\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_rf_model_1))\n",
    "\n",
    "\n",
    "#SVC\n",
    "sv_model_1 = SVC(random_state = 0)\n",
    "sv_model_1.fit(X_train, Y_train)\n",
    "y_hat_sv_model_1 = sv_model_1.predict(X_test)\n",
    "model_attrib['model_names'].append('sv_model_1')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_sv_model_1))\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_sv_model_1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGDClassifier\n",
    "from  sklearn.linear_model import SGDClassifier as SDG\n",
    "sg_model_1 = SDG(random_state = 0)\n",
    "sg_model_1.fit(X_train, Y_train)\n",
    "y_hat_sg_model_1 = sg_model_1.predict(X_test)\n",
    "model_attrib['model_names'].append('sg_model_1')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_sg_model_1))\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_sg_model_1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating features set 2 by dropping 'Age' Column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data2 = X_data.drop(['Age'], axis  = 1)\n",
    "X_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2 = X_train.drop(['Age'], axis  = 1), X_test.drop(['Age'], axis  = 1)\n",
    "print(X_train2.shape, X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression model\n",
    "lr_model_2 = LR()\n",
    "lr_model_2.fit(X_train2, Y_train)\n",
    "y_hat_lr_model_2 = lr_model_2.predict(X_test2)\n",
    "model_attrib['model_names'].append('lr_model_2')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_lr_model_2))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_lr_model_2))\n",
    "\n",
    "#RandomForestRegressor\n",
    "rf_model_2 = RFR(random_state = 0)\n",
    "rf_model_2.fit(X_train2, Y_train)\n",
    "y_hat_rf_model_2 = rf_model_2.predict(X_test2)\n",
    "model_attrib['model_names'].append('rf_model_2')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_rf_model_2))\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_rf_model_2))\n",
    "\n",
    "\n",
    "\n",
    "#SVC\n",
    "sv_model_2 = SVC(random_state = 0)\n",
    "sv_model_2.fit(X_train2, Y_train)\n",
    "y_hat_sv_model_2 = sv_model_2.predict(X_test2)\n",
    "model_attrib['model_names'].append('sv_model_2')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_sv_model_2))\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_sv_model_2))\n",
    "\n",
    "\n",
    "#SGDClassifier\n",
    "sg_model_2 = SDG(random_state = 0)\n",
    "sg_model_2.fit(X_train2, Y_train)\n",
    "y_hat_sg_model_2 = sg_model_2.predict(X_test2)\n",
    "model_attrib['model_names'].append('sg_model_2')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_sg_model_2))\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_sg_model_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LR model3 by manual tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression model\n",
    "lr_model_3 = LR(normalize = True)\n",
    "lr_model_3.fit(X_train, Y_train)\n",
    "y_hat_lr_model_3 = lr_model_3.predict(X_test)\n",
    "model_attrib['model_names'].append('lr_model_3')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_lr_model_3))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_lr_model_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LR model4 using manual hyperparameter tuning features set 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression model\n",
    "lr_model_4 = LR(normalize = True)\n",
    "lr_model_4.fit(X_train2, Y_train)\n",
    "y_hat_lr_model_4 = lr_model_4.predict(X_test2)\n",
    "model_attrib['model_names'].append('lr_model_4')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_lr_model_4))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_lr_model_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Lasso and ElasticNet algo to make our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso as LS\n",
    "ls_model_1 = LS(random_state = 0)\n",
    "ls_model_1.fit(X_train, Y_train)\n",
    "y_hat_ls_model_1 = ls_model_1.predict(X_test)\n",
    "model_attrib['model_names'].append('ls_model_1')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_ls_model_1))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_ls_model_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet as EN\n",
    "en_model_1 = EN(random_state = 0)\n",
    "en_model_1.fit(X_train, Y_train)\n",
    "y_hat_en_model_1 = en_model_1.predict(X_test)\n",
    "model_attrib['model_names'].append('en_model_1')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_en_model_1))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_en_model_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating the models using automatic Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_grid = {'max_iter' : [100, 200, 500, 1000, 2000, 5000],\n",
    "                              'warm_start':[True, False],\n",
    "             'selection': ['random', 'cyclic']}\n",
    "\n",
    "gscv_en = GridSearchCV(EN(random_state = 0), param_grid =hp_grid, n_jobs = 5, cv = 5, verbose = 10 )\n",
    "gscv_en.fit(X_data, df_raw_data_copy.Product_Purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_en.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model_2 = EN(random_state = 0, max_iter = 100, selection = 'random', warm_start = True)\n",
    "en_model_2.fit(X_train, Y_train)\n",
    "y_hat_en_model_2 = en_model_2.predict(X_test)\n",
    "model_attrib['model_names'].append('en_model_2')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_en_model_2))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_en_model_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_en = GridSearchCV(LS(random_state = 0), param_grid =hp_grid, n_jobs = 5, cv = 5, verbose = 10 )\n",
    "gscv_en.fit(X_data, df_raw_data_copy.Product_Purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_en.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_model_2 = LS(random_state = 0, max_iter = 100, selection = 'random', warm_start = True)\n",
    "ls_model_2.fit(X_train, Y_train)\n",
    "y_hat_ls_model_2 = ls_model_2.predict(X_test)\n",
    "model_attrib['model_names'].append('ls_model_2')\n",
    "model_attrib['model_feature_counts'].append(X_train.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_ls_model_2))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_ls_model_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso and ElasticNet mdoel using the automated Hyperparamter Tuning and feature set2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_model_3 = LS(random_state = 0, max_iter = 100, selection = 'random', warm_start = True)\n",
    "ls_model_3.fit(X_train2, Y_train)\n",
    "y_hat_ls_model_3 = ls_model_3.predict(X_test2)\n",
    "model_attrib['model_names'].append('ls_model_3')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_ls_model_3))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_ls_model_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model_3 = EN(random_state = 0, max_iter = 100, selection = 'random', warm_start = True)\n",
    "en_model_3.fit(X_train2, Y_train)\n",
    "y_hat_en_model_3 = en_model_3.predict(X_test2)\n",
    "model_attrib['model_names'].append('en_model_3')\n",
    "model_attrib['model_feature_counts'].append(X_train2.shape[1])\n",
    "model_attrib['model_feature_names'].append(list(X_train2.columns))\n",
    "model_attrib['model_r2_scores'].append(r2_score(Y_test, y_hat_en_model_3))\n",
    "\n",
    "model_attrib['model_mae_scores'].append(mean_absolute_error(Y_test, y_hat_en_model_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_eval_table(model_attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "According to our above table the most suitable model is en_model_2 we can also take ls_model_2, \n",
    "the one with automated Hyperparameter Tuning.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
